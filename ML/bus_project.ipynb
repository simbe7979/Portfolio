{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc960c-c5ba-43b7-ad43-6ad02456bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopy.distance\n",
    "import random\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.chdir(r\"C:/Jupyter/229255_bus_riders_at_rush_hour_data\")\n",
    "\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from folium.plugins import MarkerCluster\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca6aae-6747-4e0e-aa36-4f37ee2d6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "bts = pd.read_csv(\"bus_bts.csv\")\n",
    "\n",
    "train.shape, test.shape, bts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735e00b-ac20-4d20-b86e-83a11e65d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요일\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test['weekday'] = test['date'].dt.weekday\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3f6a5-23fc-45ed-a043-8e0f8f0acce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요일\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test['weekday'] = test['date'].dt.weekday\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f099128-c806-4357-a39f-a35cad45febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bus_route_id_weekday\n",
    "# bus_route_id_weekday = bus_route_id + weekday\n",
    "train['bus_route_id_weekday'] = train['bus_route_id'].astype(str) + ',' + train['weekday'].astype(str) \n",
    "test['bus_route_id_weekday'] = test['bus_route_id'].astype(str) + ',' + test['weekday'].astype(str) \n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7aeff-9ffb-4545-8179-72f53a09cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# station_code_weekday\n",
    "# station_code_weekday = station_code + weekday\n",
    "train['station_code_weekday'] = train['station_code'].astype(str) + ',' + train['weekday'].astype(str)\n",
    "test['station_code_weekday'] = test['station_code'].astype(str) + ',' + test['weekday'].astype(str)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6976359e-83b2-4eda-8c92-93bc71c18e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# route_station_weekday\n",
    "# route_station_weekday = route_station + weekay\n",
    "train['route_station_weekday'] = train['route_station'].astype(str) + ',' + train['weekday'].astype(str) \n",
    "test['route_station_weekday'] = test['route_station'].astype(str) + ',' + test['weekday'].astype(str)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeffa707-dd62-4b30-9013-5114c4c39b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on_time\n",
    "# bts.csv 데이터에서 geton_time 열에서 시간대만 추출하여 on_time 컬럼을 만듬\n",
    "bts['on_time']  = bts['geton_time'].apply(lambda x : x[:2])\n",
    "\n",
    "bts.iloc[bts.query('on_time == \"06\"').index,13] = '6~7_ride'\n",
    "bts.iloc[bts.query('on_time == \"07\"').index,13] = '7~8_ride'\n",
    "bts.iloc[bts.query('on_time == \"08\"').index,13] = '8~9_ride'\n",
    "bts.iloc[bts.query('on_time == \"09\"').index,13] = '9~10_ride'\n",
    "bts.iloc[bts.query('on_time == \"10\"').index,13] = '10~11_ride'\n",
    "bts.iloc[bts.query('on_time == \"11\"').index,13] = '11~12_ride'\n",
    "\n",
    "bts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d25d56-0410-4230-837c-2a643b5faed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 승 하차 시간대 통합 변수 (t ~ t+2)\n",
    "# t~t+1, t+1~t+2 시간대 승하차인원을 합하여 t~t+2 시간대 승하차인원 변수를 만듬\n",
    "train['68a']=train['6~7_ride']+train['7~8_ride'] \n",
    "train['810a']=train['8~9_ride']+train['9~10_ride']\n",
    "train['1012a']=train['10~11_ride']+train['11~12_ride']\n",
    "\n",
    "train['68b']=train['6~7_takeoff']+train['7~8_takeoff'] \n",
    "train['810b']=train['8~9_takeoff']+train['9~10_takeoff']\n",
    "train['1012b']=train['10~11_takeoff']+train['11~12_takeoff']\n",
    "\n",
    "test['68a']=test['6~7_ride']+test['7~8_ride']\n",
    "test['810a']=test['8~9_ride']+test['9~10_ride']\n",
    "test['1012a']=test['10~11_ride']+test['11~12_ride']\n",
    "\n",
    "test['68b']=test['6~7_takeoff']+test['7~8_takeoff']\n",
    "test['810b']=test['8~9_takeoff']+test['9~10_takeoff']\n",
    "test['1012b']=test['10~11_takeoff']+test['11~12_takeoff']\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c011bcc-0288-4f36-ab58-8ae1bbde745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make features by using target variable\n",
    "# 우리가 최종적으로 예측해야할 것은 각 일자별(date), 버스 노선(bus_route_id) 상의 정류장(station_name)의 퇴근시간 하차인원(18~20_ride)이다.\n",
    "\n",
    "# bus_route_id, station_name, weekday의 각 조합별 퇴근시간 하차인원(18~20_ride)의 여러 통계량을 구한 후 이를 train set, test set에 모두 적용한다.\"\n",
    "# target 변수를 train, test set에 적용할 수 있는 이유는 우리가 예측해야할 id는 date, bus_rout_id, station_name으로 구성되어있기 때문이다. 즉, 각각의 노선, 정류장별로 공통적인 패턴이 존재할 수 있다.\n",
    "# 이 과정에서 NA 값이 생기는 이유는 train set에 없는 bus_route_id, station_name이 존재하기 때문이다.\n",
    "def id_statistic(ID, col1, col2):\n",
    "    \n",
    "    # mean, sum\n",
    "    rs_mean = train.groupby([ID])['18~20_ride'].agg([(col1, 'mean')]).reset_index()\n",
    "    rs_sum = train.groupby([ID])['18~20_ride'].agg([(col2, 'sum')]).reset_index()\n",
    "    rs_mean_sum = pd.merge(rs_mean, rs_sum, on=ID)\n",
    "\n",
    "    # merge\n",
    "    tr = pd.merge(train, rs_mean_sum, how='left', on=ID)\n",
    "    te = pd.merge(test, rs_mean_sum, how='left', on=ID)\n",
    "\n",
    "    # na -> mean\n",
    "    tr[col1] = tr[col1].fillna(tr[col1].mean())\n",
    "    tr[col2] = tr[col2].fillna(tr[col2].mean())\n",
    "    te[col1] = te[col1].fillna(tr[col1].mean())\n",
    "    te[col2] = te[col2].fillna(tr[col2].mean())\n",
    "    \n",
    "    return tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734dcba-00e0-47da-a690-983595f0ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = id_statistic('route_station', '1820_rs_mean', '1820_rs_sum')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d405700-fac1-41df-af69-984359626fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_id_statistics(tr, te, ID, col1, col2):\n",
    "    # 평균과 합계 데이터 추출\n",
    "    train_grouped = tr.groupby(ID).agg({col1: 'mean', col2: 'sum'}).reset_index()\n",
    "    test_grouped = te.groupby(ID).agg({col1: 'mean', col2: 'sum'}).reset_index()\n",
    "\n",
    "    # 시각화 설정\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('ID Statistics Visualization', fontsize=16)\n",
    "\n",
    "    # Train 데이터 시각화\n",
    "    sns.scatterplot(ax=axes[0, 0], x=train_grouped[ID], y=train_grouped[col1])\n",
    "    axes[0, 0].set_title(f'Train {col1} Mean by {ID}')\n",
    "    axes[0, 0].set_xlabel(ID)\n",
    "    axes[0, 0].set_ylabel(col1)\n",
    "\n",
    "    sns.scatterplot(ax=axes[0, 1], x=train_grouped[ID], y=train_grouped[col2])\n",
    "    axes[0, 1].set_title(f'Train {col2} Sum by {ID}')\n",
    "    axes[0, 1].set_xlabel(ID)\n",
    "    axes[0, 1].set_ylabel(col2)\n",
    "\n",
    "    # Test 데이터 시각화\n",
    "    sns.scatterplot(ax=axes[1, 0], x=test_grouped[ID], y=test_grouped[col1])\n",
    "    axes[1, 0].set_title(f'Test {col1} Mean by {ID}')\n",
    "    axes[1, 0].set_xlabel(ID)\n",
    "    axes[1, 0].set_ylabel(col1)\n",
    "\n",
    "    sns.scatterplot(ax=axes[1, 1], x=test_grouped[ID], y=test_grouped[col2])\n",
    "    axes[1, 1].set_title(f'Test {col2} Sum by {ID}')\n",
    "    axes[1, 1].set_xlabel(ID)\n",
    "    axes[1, 1].set_ylabel(col2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_id_statistics(train, test, 'route_station', '1820_rs_mean', '1820_rs_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156e631-56f6-4901-b419-329b32fae5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = id_statistic('bus_route_id', '1820_r_mean', '1820_r_sum')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7875ef1-ed73-4626-b8c9-422241b9d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(train, test):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle('Scatter Plot of bus_route_id vs 18~20_ride', fontsize=16)\n",
    "\n",
    "    # Train 데이터 산점도\n",
    "    sns.scatterplot(ax=axes[0], data=train, x='bus_route_id', y='1820_r_sum')\n",
    "    axes[0].set_title('Train Data')\n",
    "    axes[0].set_xlabel('Bus Route ID')\n",
    "    axes[0].set_ylabel('18~20 Ride')\n",
    "\n",
    "    # Test 데이터 산점도\n",
    "    sns.scatterplot(ax=axes[1], data=test, x='bus_route_id', y='1820_r_sum')\n",
    "    axes[1].set_title('Test Data')\n",
    "    axes[1].set_xlabel('Bus Route ID')\n",
    "    axes[1].set_ylabel('18~20 Ride')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_scatter(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b042f5-c440-4703-986b-adf0af54cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = id_statistic('station_code', '1820_s_mean', '1820_s_sum')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeafe3e-02b0-4735-9f32-07b93918983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_statistics():\n",
    "    # bus_route_id_weekday 기반 평균 계산\n",
    "    f = train.groupby(['bus_route_id_weekday'])['18~20_ride'].agg([('mean_bus_weekday_ride', 'mean')]).reset_index()\n",
    "    tr = pd.merge(train, f, how='left', on='bus_route_id_weekday')\n",
    "    te = pd.merge(test, f, how='left', on='bus_route_id_weekday')\n",
    "    tr['mean_bus_weekday_ride'] = tr['mean_bus_weekday_ride'].fillna(f['mean_bus_weekday_ride'].mean())\n",
    "    te['mean_bus_weekday_ride'] = te['mean_bus_weekday_ride'].fillna(f['mean_bus_weekday_ride'].mean())\n",
    "\n",
    "    # station_code_weekday 기반 평균 계산\n",
    "    f = train.groupby(['station_code_weekday'])['18~20_ride'].agg([('mean_station_weekday_ride', 'mean')]).reset_index()\n",
    "    tr = pd.merge(tr, f, how='left', on='station_code_weekday')\n",
    "    te = pd.merge(te, f, how='left', on='station_code_weekday')\n",
    "    tr['mean_station_weekday_ride'] = tr['mean_station_weekday_ride'].fillna(f['mean_station_weekday_ride'].mean())\n",
    "    te['mean_station_weekday_ride'] = te['mean_station_weekday_ride'].fillna(f['mean_station_weekday_ride'].mean())\n",
    "\n",
    "    # route_station_weekday 기반 평균 계산\n",
    "    f = train.groupby(['route_station_weekday'])['18~20_ride'].agg([('mean_route_station_weekday_ride', 'mean')]).reset_index()\n",
    "    tr = pd.merge(tr, f, how='left', on='route_station_weekday')\n",
    "    te = pd.merge(te, f, how='left', on='route_station_weekday')\n",
    "    tr['mean_route_station_weekday_ride'] = tr['mean_route_station_weekday_ride'].fillna(f['mean_route_station_weekday_ride'].mean())\n",
    "    te['mean_route_station_weekday_ride'] = te['mean_route_station_weekday_ride'].fillna(f['mean_route_station_weekday_ride'].mean())\n",
    "\n",
    "    return tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78d7ae-f88e-4942-8f80-694d346e539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = mean_statistics()\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe3ef0-4ade-4ca2-b1fc-5b43fdff81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def congestion():\n",
    "    # 버스 노선별 총 승객 수 계산\n",
    "    df = train.groupby(['bus_route_id'])['18~20_ride'].agg([('passenger', 'sum')]).reset_index()\n",
    "\n",
    "    # 승객 수에 따른 혼잡도 레벨 지정\n",
    "    def get_congestion_level(passenger):\n",
    "        if passenger > 10000:\n",
    "            return 7\n",
    "        elif passenger > 5000:\n",
    "            return 6\n",
    "        elif passenger > 2000:\n",
    "            return 5\n",
    "        elif passenger > 700:\n",
    "            return 4\n",
    "        elif passenger > 200:\n",
    "            return 3\n",
    "        elif passenger > 50:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    df['congestion'] = df['passenger'].apply(get_congestion_level)\n",
    "    df = df[['bus_route_id', 'congestion']]\n",
    "\n",
    "    # 학습 데이터와 테스트 데이터에 혼잡도 정보 병합\n",
    "    tr = pd.merge(train, df, how='left', on='bus_route_id')\n",
    "    te = pd.merge(test, df, how='left', on='bus_route_id')\n",
    "\n",
    "    # 테스트 데이터의 결측치 처리\n",
    "    te['congestion'] = te['congestion'].fillna(df['congestion'].median())\n",
    "\n",
    "    return tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329cd23d-dc81-47da-ada4-d878e9ee3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = congestion()\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4365136-6c5b-4a13-b2ad-a0e595a3951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location\n",
    "# location = latitude + longitude\n",
    "train['location'] = train['latitude'].astype(str) + ',' + train['longitude'].astype(str)\n",
    "test['location'] = test['latitude'].astype(str) + ',' + test['longitude'].astype(str)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ff046-d6d5-43bb-a73b-b7dd1882c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make cue column\n",
    "train['cue']=0\n",
    "test['cue']=1\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0e8a0-5837-4597-bcd3-9ba98ba47ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morning() :\n",
    "    \n",
    "    # merge\n",
    "    data = pd.concat([train, test])\n",
    "    \n",
    "    a = data.groupby(['route_station'])['1012a'].agg({'sum', 'mean'}).reset_index()\n",
    "    a.columns = ['route_station', '1012a_sum','1012a_mean']\n",
    "\n",
    "    b = data.groupby(['route_station'])['1012b'].agg({'sum', 'mean'}).reset_index()\n",
    "    b.columns = ['route_station', '1012b_sum','1012b_mean']\n",
    "    b = b[['1012b_sum','1012b_mean']]\n",
    "\n",
    "    c = data.groupby(['route_station'])['10~11_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    c.columns = ['route_station', '10~11_ride_sum','10~11_ride_mean']\n",
    "    c = c[['10~11_ride_sum','10~11_ride_mean']]\n",
    "\n",
    "    d = data.groupby(['route_station'])['10~11_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    d.columns = ['route_station', '10~11_takeoff_sum','10~11_takeoff_mean']\n",
    "    d = d[['10~11_takeoff_sum','10~11_takeoff_mean']]\n",
    "\n",
    "    e = data.groupby(['route_station'])['11~12_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    e.columns = ['route_station', '11~12_ride_sum','11~12_ride_mean']\n",
    "    e = e[['11~12_ride_sum','11~12_ride_mean']]\n",
    "\n",
    "    f = data.groupby(['route_station'])['11~12_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    f.columns = ['route_station', '11~12_takeoff_sum','11~12_takeoff_mean']\n",
    "    f = f[['11~12_takeoff_sum','11~12_takeoff_mean']]\n",
    "\n",
    "    g = data.groupby(['route_station'])['1820_r_mean'].agg({'sum', 'mean'}).reset_index()\n",
    "    g.columns = ['route_station', '1820_r_mean_sum','1820_r_mean_mean']\n",
    "    g = g[['1820_r_mean_sum','1820_r_mean_mean']]\n",
    "\n",
    "    h = data.groupby(['route_station'])['1820_r_sum'].agg({'sum', 'mean'}).reset_index()\n",
    "    h.columns = ['route_station', '1820_r_sum_sum','1820_r_sum_mean']\n",
    "    h = h[['1820_r_sum_sum','1820_r_sum_mean']]\n",
    "\n",
    "    i = data.groupby(['route_station'])['1820_rs_mean'].agg({'sum', 'mean'}).reset_index()\n",
    "    i.columns = ['route_station', '1820_rs_mean_sum','1820_rs_mean_mean']\n",
    "    i = i[['1820_rs_mean_sum','1820_rs_mean_mean']]\n",
    "\n",
    "    j = data.groupby(['route_station'])['1820_rs_sum'].agg({'sum', 'mean'}).reset_index()\n",
    "    j.columns = ['route_station', '1820_rs_sum_sum','1820_rs_sum_mean']\n",
    "    j = j[['1820_rs_sum_sum','1820_rs_sum_mean']]\n",
    "\n",
    "    k = data.groupby(['route_station'])['1820_s_mean'].agg({'sum', 'mean'}).reset_index()\n",
    "    k.columns = ['route_station', '1820_s_mean_sum','1820_s_mean_mean']\n",
    "    k = k[['1820_s_mean_sum','1820_s_mean_mean']]\n",
    "\n",
    "    l = data.groupby(['route_station'])['1820_s_sum'].agg({'sum', 'mean'}).reset_index()\n",
    "    l.columns = ['route_station', '1820_s_sum_sum','1820_s_sum_mean']\n",
    "    l = l[['1820_s_sum_sum','1820_s_sum_mean']]\n",
    "\n",
    "    m = data.groupby(['route_station'])['1820_w_mean'].agg({'sum', 'mean'}).reset_index()\n",
    "    m.columns = ['route_station', '1820_w_mean_sum','1820_w_mean_mean']\n",
    "    m = m[['1820_w_mean_sum','1820_w_mean_mean']]\n",
    "\n",
    "    n = data.groupby(['route_station'])['1820_w_sum'].agg({'sum', 'mean'}).reset_index()\n",
    "    n.columns = ['route_station', '1820_w_sum_sum','1820_w_sum_mean']\n",
    "    n = n[['1820_w_sum_sum','1820_w_sum_mean']]\n",
    "\n",
    "    o = data.groupby(['route_station'])['68a'].agg({'sum', 'mean'}).reset_index()\n",
    "    o.columns = ['route_station', '68a_sum','68a_mean']\n",
    "    o = o[['68a_sum','68a_mean']]\n",
    "\n",
    "    p = data.groupby(['route_station'])['68b'].agg({'sum', 'mean'}).reset_index()\n",
    "    p.columns = ['route_station', '68b_sum','68b_mean']\n",
    "    p = p[['68b_sum','68b_mean']]\n",
    "\n",
    "    q = data.groupby(['route_station'])['6~7_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    q.columns = ['route_station', '6~7_ride_sum','6~7_ride_mean']\n",
    "    q = q[['6~7_ride_sum','6~7_ride_mean']]\n",
    "\n",
    "    r = data.groupby(['route_station'])['6~7_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    r.columns = ['route_station', '6~7_takeoff_sum','6~7_takeoff_mean']\n",
    "    r = r[['6~7_takeoff_sum','6~7_takeoff_mean']]\n",
    "\n",
    "    s = data.groupby(['route_station'])['7~8_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    s.columns = ['route_station', '7~8_ride_sum','7~8_ride_mean']\n",
    "    s = s[['7~8_ride_sum','7~8_ride_mean']]\n",
    "\n",
    "    t = data.groupby(['route_station'])['7~8_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    t.columns = ['route_station', '7~8_takeoff_sum','7~8_takeoff_mean']\n",
    "    t = t[['7~8_takeoff_sum','7~8_takeoff_mean']]\n",
    "\n",
    "    u = data.groupby(['route_station'])['810a'].agg({'sum', 'mean'}).reset_index()\n",
    "    u.columns = ['route_station', '810a_sum','810a_mean']\n",
    "    u = u[['810a_sum','810a_mean']]\n",
    "\n",
    "    v = data.groupby(['route_station'])['810b'].agg({'sum', 'mean'}).reset_index()\n",
    "    v.columns = ['route_station', '810b_sum','810b_mean']\n",
    "    v = v[['810b_sum','810b_mean']]\n",
    "\n",
    "    w = data.groupby(['route_station'])['8~9_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    w.columns = ['route_station', '8~9_ride_sum','8~9_ride_mean']\n",
    "    w = w[['8~9_ride_sum','8~9_ride_mean']]\n",
    "\n",
    "    x = data.groupby(['route_station'])['8~9_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    x.columns = ['route_station', '8~9_takeoff_sum','8~9_takeoff_mean']\n",
    "    x = x[['8~9_takeoff_sum','8~9_takeoff_mean']]\n",
    "\n",
    "    y = data.groupby(['route_station'])['9~10_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    y.columns = ['route_station', '9~10_ride_sum','9~10_ride_mean']\n",
    "    y = y[['9~10_ride_sum','9~10_ride_mean']]\n",
    "\n",
    "    z = data.groupby(['route_station'])['9~10_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    z.columns = ['route_station', '9~10_takeoff_sum','9~10_takeoff_mean']\n",
    "    z = z[['9~10_takeoff_sum','9~10_takeoff_mean']]\n",
    "    \n",
    "    df = pd.concat([a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z],axis=1)\n",
    "    df = pd.merge(data, df, how='left', on='route_station')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee172b-1744-434a-abab-64363bb0488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = morning()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678bed44-5542-4edb-94ba-eb769132005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배차 간격\n",
    "train['bus_route_id'] = train['bus_route_id'].astype(np.int64)\n",
    "test['bus_route_id'] = test['bus_route_id'].astype(np.int64)\n",
    "\n",
    "bts['geton_time2'] = pd.to_datetime(bts['geton_time'])\n",
    "\n",
    "f = bts.groupby(['geton_date','geton_time2','geton_station_code','bus_route_id'])['user_count'].\\\n",
    "agg([('탑승객_수','sum')]).reset_index().\\\n",
    "sort_values(by=['geton_date','geton_station_code','bus_route_id','geton_time2'], ascending=True).reset_index()\n",
    "\n",
    "f['index'] = list(range(0,len(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef77a8b-b2de-413e-bc02-f353b7ef19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = []\n",
    "\n",
    "# for i in range(0,len(f)-1):\n",
    "\n",
    "#     if ((f.iloc[i].geton_date == f.iloc[i+1].geton_date) &\\\n",
    "#         (f.iloc[i].geton_station_code == f.iloc[i+1].geton_station_code) &\\\n",
    "#         (f.iloc[i].bus_route_id == f.iloc[i+1].bus_route_id)):\n",
    "\n",
    "#         time.append(f.iloc[i+1].geton_time2 - f.iloc[i].geton_time2)\n",
    "\n",
    "#     else:\n",
    "#         time.append(0)\n",
    "\n",
    "# time.insert(0, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b1a5b-2a1b-4e38-ae43-eaa753911e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sec(time_str):\n",
    "\n",
    "#     h, m, s = time_str.split(':')\n",
    "\n",
    "#     return int(h) * 3600 + int(m) * 60 + int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a1919-b5c7-4248-9c39-a4616271f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bus_interval() :\n",
    "#     f['time'] = time\n",
    "#     f['time2'] = f['time'].astype(str).str[7:]\n",
    "\n",
    "#     interval = f.copy()\n",
    "#     interval['time2'] = interval['time2'].astype(str).replace('','00:00:00')\n",
    "#     interval['bus_route_id'] = interval['bus_route_id'].astype(object)\n",
    "\n",
    "#     time4 = []\n",
    "\n",
    "#     for i in interval['time2'] :\n",
    "#         time4.append(get_sec(i))\n",
    "\n",
    "#     interval['time4'] = time4\n",
    "#     interval['time4'] = (interval['time4'] / 60).astype(int)\n",
    "\n",
    "#     interval = interval[interval['time4'] > 3] # 간격이 3분보다 작은 것 제외\n",
    "#     interval = interval[interval['time4'] < 180] # 간격이 3시간보다 큰 것 제외\n",
    "\n",
    "#     interval = interval.groupby('bus_route_id')['time4'].agg([('bus_interval', 'mean')]).reset_index()\n",
    "#     interval['bus_interval'] = interval['bus_interval'].astype(int)\n",
    "\n",
    "#     # 나중에 시간을 절약하기 위해 csv 파일로 저장\n",
    "#     interval.to_csv('bus_interval_final.csv', index = False)\n",
    "\n",
    "#     print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d84972-f4b3-4520-8241-c6d1751de17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bus_interval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14706c4-a876-4113-a151-0fc9c97e5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_interval = pd.read_csv(\"bus_interval_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d158543-36ab-4c68-8d51-e6f8d1535bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bus_route_id'] = data['bus_route_id'].astype(np.int64)\n",
    "\n",
    "data['bus_route_id'] = data['bus_route_id'].astype(np.int64)\n",
    "\n",
    "data['bus_interval'] = data['bus_interval'].fillna(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4ce0b-12d0-45bc-985a-a92d28647ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df_encode = data[['bus_route_id','station_code', 'route_station_weekday', 'route_station']]\n",
    "df_encoded = df_encode.apply(labelencoder.fit_transform)\n",
    "\n",
    "data['bus_route_id2']=df_encoded['bus_route_id']\n",
    "data['station_code2']=df_encoded['station_code']\n",
    "data['route_station_weekday2']=df_encoded['route_station_weekday']\n",
    "data['route_station2']=df_encoded['route_station']\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75f5be-2876-45cc-af42-6837d2138431",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['in_out'].value_counts()\n",
    "data['in_out'] = data['in_out'].map({'시내':0,'시외':1})\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc02e05-28a1-40f3-8f93-6ad4ff784ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from geopy.distance import geodesic\n",
    "\n",
    "coords_jejusi = (33.500770, 126.522761) #제주시의 위도 경도\n",
    "data['dis_jejusi'] = [geodesic((data['latitude'].iloc[i], data['longitude'].iloc[i]), coords_jejusi).km for i in range(len(data))]\n",
    "\n",
    "coords_jejusicheong1 = (33.49892, 126.53035) #제주시청(광양방면)의 위도 경도\n",
    "coords_jejuairport = (33.50661, 126.49345) #제주국제공항(구제주방면)의 위도 경도\n",
    "coords_hallahosp = (33.48963, 126.486) #한라병원의 위도 경도\n",
    "coords_rotary = (33.49143, 126.49678) # 제주도청신제주로터리의 위도 경도\n",
    "coords_jejucenterhigh = (33.48902, 126.5392) #제주중앙여자고등학교의 위도 경도\n",
    "coords_jejumarket = (33.51315, 126.52706) #동문시장의 위도 경도\n",
    "coords_jejusclass = (33.47626, 126.48141) #제주고등학교/중흥S클래스의 위도 경도\n",
    "coords_centerroad = (33.51073, 126.5239) #중앙로(국민은행)의 위도 경도\n",
    "coords_fiveway = (33.48667, 126.48092) # 노형오거리의 위도 경도\n",
    "coords_law = (33.49363, 126.53476) # 제주지방법원(광양방면)의 위도 경도\n",
    "\n",
    "data['dis_jejusicheong1'] = [geodesic((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejusicheong1).km for i in range(len(data))]\n",
    "data['dis_jejuairport'] = [geodesic((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejuairport).km for i in range(len(data))]\n",
    "data['dis_hallahosp'] = [geodesic((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_hallahosp).km for i in range(len(data))]\n",
    "data['dis_rotary'] = [geodesic((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_rotary).km for i in range(len(data))]\n",
    "data['dis_jejucenterhigh'] = [geodesic((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejucenterhigh).km for i in range(len(data))]\n",
    "data['dis_jejumarket'] = [geodesic((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejumarket).km for i in range(len(data))]\n",
    "data['dis_jejusclass'] = [geodesic((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejusclass).km for i in range(len(data))]\n",
    "data['dis_centerroad'] = [geodesic((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_centerroad).km for i in range(len(data))]\n",
    "data['dis_fiveway'] = [geodesic((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_fiveway).km for i in range(len(data))]\n",
    "data['dis_law'] = [geodesic((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_law).km for i in range(len(data))]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4e2a3-ead4-4ad8-9f2d-1f158aa9585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출근 시간의 총 승객 수\n",
    "data['ride_sum'] = data['6~7_ride'] + data['7~8_ride'] + data['8~9_ride'] + data['9~10_ride'] + data['10~11_ride'] + data['11~12_ride'] \n",
    "data['takeoff_sum'] = data['6~7_takeoff'] + data['7~8_takeoff'] + data['8~9_takeoff'] + data['9~10_takeoff'] + data['10~11_takeoff'] + data['11~12_takeoff'] \n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ef1ec-be76-44f1-add2-17006f5c3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 및 시간대 별 총 승객수\n",
    "f = data.groupby('date')['6~7_ride'].agg([('6~7_all_ride_number', 'sum')]).reset_index()\n",
    "data = pd.merge(data, f, how='left')\n",
    "\n",
    "f = data.groupby('date')['7~8_ride'].agg([('7~8_all_ride_number', 'sum')]).reset_index()\n",
    "data = pd.merge(data, f, how='left')\n",
    "\n",
    "f = data.groupby('date')['8~9_ride'].agg([('8~9_all_ride_number', 'sum')]).reset_index()\n",
    "data = pd.merge(data, f, how='left')\n",
    "\n",
    "f = data.groupby('date')['9~10_ride'].agg([('9~10_all_ride_number', 'sum')]).reset_index()\n",
    "data = pd.merge(data, f, how='left')\n",
    "\n",
    "f = data.groupby('date')['10~11_ride'].agg([('10~11_all_ride_number', 'sum')]).reset_index()\n",
    "data = pd.merge(data, f, how='left')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f232b-9aef-44fb-883d-52dd4dce725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주말, 주중\n",
    "def h(x):\n",
    "    if x ==5:\n",
    "        return 1\n",
    "    elif x==6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['weekend'] = data['weekday'].apply(h)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90447ddb-e650-449d-8431-274669d3debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연휴\n",
    "def g(x):\n",
    "    if x in ['2019-09-12','2019-09-13','2019-09-14','2019-10-03','2019-10-09']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['holiday'] = data['date'].apply(g) \n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1cba3-ca41-49de-81f2-d795be378cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요일 별 평균 승객 수\n",
    "def week_mean() :\n",
    "\n",
    "    df = data.reset_index(drop=True)\n",
    "    df.groupby('weekday')['18~20_ride'].mean()\n",
    "    df['weekdaymean']= 1\n",
    "\n",
    "    index0 = df.query('weekday==0').index\n",
    "    index1 = df.query('weekday==1').index\n",
    "    index2 = df.query('weekday==2').index\n",
    "    index3 = df.query('weekday==3').index\n",
    "    index4 = df.query('weekday==4').index\n",
    "    index5 = df.query('weekday==5').index\n",
    "    index6 = df.query('weekday==6').index\n",
    "\n",
    "    # 일별 18~20_ride 평균\n",
    "    df.iloc[index0,-1] = 1.343710\n",
    "    df.iloc[index1,-1] = 1.375319\n",
    "    df.iloc[index2,-1] = 1.430856\n",
    "    df.iloc[index3,-1] = 1.256710\n",
    "    df.iloc[index4,-1] = 1.067439\n",
    "    df.iloc[index5,-1] = 1.062123\n",
    "    df.iloc[index6,-1] = 1.034282\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c9143-8da3-4efb-8293-92119b0cf83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = week_mean()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1311c43-8b24-4daf-ad6d-a45a617ecc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시내 및 시외버스 별 평균 탑승 승객\n",
    "data['in_out_mean'] = 1\n",
    "inindex = data.query('in_out == \"시내\"').index\n",
    "outindex = data.query('in_out == \"시외\"').index\n",
    "\n",
    "data.iloc[inindex,-1] = 1.228499\n",
    "data.iloc[outindex,-1] = 2.044345\n",
    "data['congestion'] = data['congestion'].astype('int64')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591382d0-a59a-4d89-82b8-a474454a3bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 측정소와 정류장 사이 거리 계산\n",
    "def dist() :\n",
    "    jeju=(33.51411, 126.52969) # 제주 측정소 근처\n",
    "    gosan=(33.29382, 126.16283) #고산 측정소 근처\n",
    "    seongsan=(33.38677, 126.8802) #성산 측정소 근처\n",
    "    po=(33.24616, 126.5653) #서귀포 측정소 근처\n",
    "\n",
    "    t1 = [geodesic( (i,j), jeju).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "    t2 = [geodesic( (i,j), gosan).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "    t3 = [geodesic( (i,j), seongsan).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "    t4 = [geodesic( (i,j), po).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "\n",
    "    data['dis_jeju'] = t1\n",
    "    data['dis_gosan']=t2\n",
    "    data['dis_seongsan']=t3\n",
    "    data['dis_po']=t4\n",
    "\n",
    "    total = pd.DataFrame(list(zip( t1,t2,t3,t4)),columns=['jeju','gosan','seongsan','po'] )\n",
    "    data['dist_name'] = total.apply(lambda x: x.argmin(), axis=1)\n",
    "    \n",
    "    return data\n",
    "data = dist()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271b49a-3822-4a8c-87b8-ad93b6872892",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dist_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46652d45-442d-4130-aa01-01622912eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain3 = pd.read_csv(\"rain3.csv\")\n",
    "\n",
    "# train, test의 변수명과 통일시키고, NaN의 값은 0.0000으로 변경\n",
    "rain3 = rain3.rename(columns={\"일시\":\"date\",\"지점\":\"dist_name\"})\n",
    "rain3 = rain3.fillna(0.00000)\n",
    "rain3['date'] = pd.to_datetime(rain3['date'])\n",
    "\n",
    "rain3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de360618-e468-42d8-983b-0dc5298c1703",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['dist_name'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0469f5a-3749-4331-acab-0ab6d18e7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dist_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefabf4-0f4d-4f59-b143-0d7a197b7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rain3['dist_name'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16006a3-cccd-4f9b-892a-a52a25b48475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist() :\n",
    "    jeju=(33.51411, 126.52969) # 제주 측정소 근처\n",
    "    gosan=(33.29382, 126.16283) #고산 측정소 근처\n",
    "    seongsan=(33.38677, 126.8802) #성산 측정소 근처\n",
    "    po=(33.24616, 126.5653) #서귀포 측정소 근처\n",
    "\n",
    "    t1 = [geodesic( (i,j), jeju).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "    t2 = [geodesic( (i,j), gosan).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "    t3 = [geodesic( (i,j), seongsan).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "    t4 = [geodesic( (i,j), po).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "\n",
    "    data['dis_jeju'] = t1\n",
    "    data['dis_gosan']=t2\n",
    "    data['dis_seongsan']=t3\n",
    "    data['dis_po']=t4\n",
    "\n",
    "    total = pd.DataFrame(list(zip( t1,t2,t3,t4)),columns=['jeju','gosan','seongsan','po'] )\n",
    "    data['dist_name'] = total.apply(lambda x: x.argmin(), axis=1)\n",
    "rain3['dist_name']\n",
    "data['dist_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ec1c4-deaa-4ca5-a873-1761865996bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자형으로 변환\n",
    "rain3['dist_name'] = rain3['dist_name'].str.replace('gosan', '0')\n",
    "rain3['dist_name'] = rain3['dist_name'].str.replace('seongsan', '1')\n",
    "rain3['dist_name'] = rain3['dist_name'].str.replace('jeju', '2')\n",
    "rain3['dist_name'] = rain3['dist_name'].str.replace('po', '3')\n",
    "rain3['dist_name'] = rain3['dist_name'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a706779-9b46-44fe-8610-3d4e2f25d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rain3['dist_name'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81c79e-855d-4923-8718-9b19aa3b4b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, rain3, how='left',on=['dist_name','date'])\n",
    "data = pd.get_dummies(data,columns=['dist_name'])\n",
    "# data = pd.get_dummies(data,columns=['si'])\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde9ccc-c023-485a-bbd9-1497e800f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rainy_day\n",
    "# 비 오는날=1, 비 안오는 날=0\n",
    "def f(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f602d0-ee68-47b5-86c2-406b5b9c4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rainy_day'] = data['강수량(mm)'].apply(f)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe2fa0-c757-462b-a661-183f0f4e14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 승 하차 시간대 통합 변수 (t ~ t+3)\n",
    "# t~t+1, t+1~t+2, t+2~t+3 시간대 승하차인원을 합하여 t~t+3 시간대 승하차인원 변수를 만듬\n",
    "data['69a'] = data['6~7_ride']+data['7~8_ride']+data['8~9_ride']\n",
    "data['912a']=data['9~10_ride']+data['10~11_ride']+data['11~12_ride']\n",
    "\n",
    "data['69b'] = data['6~7_takeoff']+data['7~8_takeoff']+data['8~9_takeoff']\n",
    "data['912b'] = data['9~10_takeoff']+data['10~11_takeoff']+data['11~12_takeoff']\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c266f36-a4c2-4ae6-bd97-1e048e81d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93136c-478b-4ade-b7c3-66a55b59c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240c260-c506-4548-9c8f-357b993e3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2867a6c4-e170-4293-81b1-6e41b1f6c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset\n",
    "# 'cue' 열의 값이 0인 행을 train_data로\n",
    "train_data = data[data['cue'] == 0].reset_index(drop=True)\n",
    "# 'cue' 열의 값이 1인 행을 test_data로\n",
    "test_data = data[data['cue'] == 1].reset_index(drop=True)\n",
    "\n",
    "# 데이터프레임의 크기 출력\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "\n",
    "# 인덱스 확인\n",
    "print(\"Train data index:\", train_data.index)\n",
    "print(\"Test data index:\", test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e51c84-475b-4f36-968f-e2031633b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약통계량을 통한 변수를 만드는 과정에서 NA가 발생한다.\n",
    "\n",
    "# target variable을 분리한 후 데이터를 저장한다.\n",
    "\n",
    "y_train = train_data[['18~20_ride']]\n",
    "train_data.shape, test_data.shape, y_train.shape\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e55009-2120-491c-ba3b-ec9eaf6e5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var_0=['in_out','latitude','longitude','6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride',\n",
    "           '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',\n",
    "           'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', \n",
    "           'dis_jejusi', 'dis_jejusicheong1','dis_jejuairport','dis_hallahosp', 'dis_rotary','dis_jejucenterhigh',\n",
    "           'dis_jejumarket', 'dis_centerroad', 'dis_jejusclass', 'dis_fiveway', 'dis_law',\n",
    "           'weekend', 'holiday', 'ride_sum', 'takeoff_sum', '1820_rs_mean', '1820_r_mean', '1820_s_mean', 'congestion',\n",
    "           'station_code2', 'bus_route_id2', '일강수_10', '현재일기_10', '체감온도_10',\n",
    "           '6~7_all_ride_number', '7~8_all_ride_number', '8~9_all_ride_number', '9~10_all_ride_number', '10~11_all_ride_number',\n",
    "           '1820_w_mean','in_out_mean','weekdaymean','adult','kids','teen','elder','adult_prop', 'kids_prop', 'teen_prop', 'elder_prop',\n",
    "           'mean_job_majorc', 'mean_job_smallc', 'mean_job_public', 'mean_job_profession', 'mean_job_self',\n",
    "           'mean_vehicle_own_rat', 'mean_avg_income', 'mean_med_income', 'mean_avg_spend', \n",
    "           'rate_job_majorc', 'rate_job_smallc', 'rate_job_public', 'rate_job_profession', 'rate_job_self', \n",
    "           'rate_vehicle_own_rat', 'rate_avg_income', 'rate_med_income','rate_avg_spend',\n",
    "           'sum_job_majorc', 'sum_job_smallc', 'sum_job_public', 'sum_job_profession', 'sum_job_self', \n",
    "           'sum_vehicle_own_rat', 'sum_avg_income', 'sum_med_income','sum_avg_spend',\n",
    "           '68a', '810a', '1012a', '68b', '810b', '1012b','69a','912a','69b','912b',\n",
    "           'dis_jeju', 'dis_gosan', 'dis_seongsan', 'dis_po', '기온(°C)', '강수량(mm)',\n",
    "           'dist_name_gosan', 'dist_name_jeju', 'dist_name_po', 'dist_name_seongsan', 'si_서귀포시', 'si_제주시',\n",
    "           'school', 'transfer', 'dong2', 'rainy_day']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b65a8-99ca-470b-9b76-ba28a91a0a80",
   "metadata": {},
   "source": [
    "## columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a153c0-6cc1-4601-a22e-3c1b9bd4536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var1 = ['in_out', 'latitude', 'longitude', '6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride', '6~7_takeoff',\n",
    " '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff', 'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4',\n",
    " 'weekday_5', 'weekday_6', 'dis_jejusi', 'dis_jejusicheong1', 'dis_jejuairport', 'dis_hallahosp', 'dis_rotary', 'dis_jejucenterhigh',\n",
    " 'dis_jejumarket', 'dis_centerroad', 'dis_jejusclass', 'dis_fiveway', 'dis_law', 'weekend', 'holiday', 'ride_sum', 'takeoff_sum', '1820_rs_mean',\n",
    " '1820_r_mean', '1820_s_mean', 'congestion', 'station_code2', 'bus_route_id2', '6~7_all_ride_number', '7~8_all_ride_number', '8~9_all_ride_number',\n",
    " '9~10_all_ride_number', '10~11_all_ride_number', b'1820_w_mean', 'in_out_mean', 'weekdaymean', 'adult', 'kids', 'teen', 'elder', '68a', '810a',\n",
    " '1012a', '68b', '810b', '1012b', '69a', '912a', '69b', '912b', 'dis_jeju', 'dis_gosan', 'dis_seongsan', 'dis_po', '기온(°C)', '강수량(mm)',\n",
    " 'rainy_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2046b8-be0f-4f07-b0b6-e8866248fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var3 = ['68a', '810a', 'bus_interval', 'dis_jejuairport', 'ride_sum', 'takeoff_sum', '1820_rs_mean', '1820_rs_sum', '1820_r_mean',\n",
    " '1820_r_sum', '1820_s_mean', '1820_s_sum', 'congestion', 'bus_route_id2', '6~7_all_ride_number', '7~8_all_ride_number', '8~9_all_ride_number',\n",
    " '1012a_mean', '1012b_sum', '10~11_ride_sum', '10~11_takeoff_sum', '11~12_ride_sum', '11~12_takeoff_sum', '1820_r_mean_sum', '1820_r_mean_mean',\n",
    " '1820_r_sum_sum', '1820_r_sum_mean', '1820_rs_mean_sum', '1820_s_mean_sum', '1820_s_mean_mean', '1820_s_sum_sum', '1820_s_sum_mean',\n",
    " '1820_w_mean_sum', '1820_w_mean_mean', '1820_w_sum_mean', '68a_sum', '68a_mean', '68b_sum', 'in_out', 'latitude', 'longitude', '6~7_ride',\n",
    " '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride', '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', \n",
    " '11~12_takeoff', 'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'dis_jejusi', '68b_mean', '6~7_ride_sum',\n",
    " '6~7_ride_mean', '6~7_takeoff_sum', '6~7_takeoff_mean', '7~8_ride_sum', '7~8_ride_mean', '7~8_takeoff_sum', '7~8_takeoff_mean', '810a_sum',\n",
    " '810b_sum', '8~9_ride_sum', '8~9_takeoff_sum', '8~9_takeoff_mean', '9~10_ride_sum', '9~10_takeoff_sum', 'route_station_weekday2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1546bba6-13cb-4cf5-bd0a-5db5c3622622",
   "metadata": {},
   "source": [
    "# LightGBM을 사용한 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0ec23-e794-4ddc-8e8f-fbecab21ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train[input_var1], y_train, test_size=0.3, random_state= 123)\n",
    "\n",
    "model = lgb.LGBMRegressor()\n",
    "model.fit(X_train1, y_train1)\n",
    "\n",
    "# feature importance 계산\n",
    "importance = model.feature_importances_\n",
    "feature_importance = pd.DataFrame({'feature': input_var1, 'importance': importance})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=True)\n",
    "\n",
    "# 교차 검증을 위한 RMSE 스코어러 정의\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "# 중요도가 낮은 피처부터 하나씩 제거하면서 모델 성능 평가\n",
    "rmse_list = []\n",
    "features_list = []\n",
    "\n",
    "for i in range(len(feature_importance)):\n",
    "    selected_features = feature_importance['feature'][i:].tolist()\n",
    "    X_train_selected = X_train1[selected_features]\n",
    "    \n",
    "    # 교차 검증을 사용하여 모델 성능 평가\n",
    "    scores = cross_val_score(model, X_train_selected, y_train1, cv=5, scoring=rmse_scorer)\n",
    "    mean_rmse = np.mean(scores)\n",
    "    \n",
    "    rmse_list.append(mean_rmse)\n",
    "    features_list.append(selected_features)\n",
    "    \n",
    "    print(f\"Removed {i} features, Mean RMSE: {mean_rmse}\")\n",
    "\n",
    "# 최적의 피처 조합 찾기\n",
    "min_rmse_index = np.argmin(rmse_list)\n",
    "best_features = features_list[min_rmse_index]\n",
    "best_rmse = rmse_list[min_rmse_index]\n",
    "\n",
    "print(f\"\\nBest Mean RMSE: {best_rmse} with features: {best_features}\")\n",
    "\n",
    "# 최적의 피처 조합 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(rmse_list)), rmse_list, marker='o')\n",
    "plt.xlabel('Number of features removed')\n",
    "plt.ylabel('Mean RMSE')\n",
    "plt.title('Mean RMSE vs Number of features removed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a5437-b115-46f3-8da4-e0dc372a88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능을 높이기 위해 중요도가 가장 높은 피처 1개 복구\n",
    "best_var1 = best_features + ['elder']\n",
    "\n",
    "# input_var3은 더이상 성능을 높일 수 없기에 Feature Selection을 진행 X\n",
    "best_var3 = input_var3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abf25cc-78e5-4eb3-9fe5-c57e25b454f0",
   "metadata": {},
   "source": [
    "## best_var1으로 학습한 LightGBM (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7409455d-e718-4528-9635-8d49aa7b207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.LGBMRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'num_leaves': [31, 50],\n",
    "    'learning_rate': [0.05],\n",
    "    'min_child_samples': [20, 50],\n",
    "    'max_depth': [-1, 10],\n",
    "    'feature_fraction': [0.8, 1.0],\n",
    "    'bagging_fraction': [0.8, 1.0],\n",
    "    'lambda_l1': [0, 0.1],\n",
    "    'lambda_l2': [0, 0.1],\n",
    "    'boosting_type': ['dart'],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = lgbm, param_grid = param_grid, cv = 3, scoring = 'neg_mean_squared_error', \n",
    "                           verbose = 1, n_jobs = -1)\n",
    "\n",
    "grid_search.fit(X_train[best_var1], y_train)\n",
    "\n",
    "print(\"Best parameters : \", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "X_test['18~20_ride'] = best_model.predict(X_test[best_var1])\n",
    "X_test[['id','18~20_ride']].to_csv(\"lgb_gridCV_best_var1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51412d09-aa5c-4df3-b02b-c05b4ff6966f",
   "metadata": {},
   "source": [
    "## best_var1으로 학습한 LightGBM (Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e5b52-7d3e-4c79-8aed-970542930c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"n_estimators\": 500,\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"dart\",\n",
    "        \"bagging_freq\": 1,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.8, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.8, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 50),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0, 0.1),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0, 0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 10)\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    scores = cross_val_score(model, X_train[best_var1], y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # 평균 RMSE 반환 (최소화하기 위해 - 붙임)\n",
    "    return -scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials = 100)  # 최적화 시도 횟수 100\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "\n",
    "best_model = lgb.LGBMRegressor(**study.best_params)\n",
    "best_model.fit(X_train[best_var1], y_train)\n",
    "X_test['18~20_ride'] = best_model.predict(X_test[best_var1])\n",
    "X_test[['id','18~20_ride']].to_csv(\"lgb_optuna_best_var1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c308c56-d8af-4585-ae21-1d0d3cc3f57d",
   "metadata": {},
   "source": [
    "## best_var3으로 학습한 LightGBM (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b9de7-27ca-4095-8241-8174b96cb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.LGBMRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'num_leaves': [31, 50],\n",
    "    'learning_rate': [0.05],\n",
    "    'min_child_samples': [20, 50],\n",
    "    'max_depth': [-1, 10],\n",
    "    'feature_fraction': [0.8, 1.0],\n",
    "    'bagging_fraction': [0.8, 1.0],\n",
    "    'lambda_l1': [0, 0.1],\n",
    "    'lambda_l2': [0, 0.1],\n",
    "    'boosting_type': ['dart'],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = lgbm, param_grid = param_grid, cv = 3, scoring = 'neg_mean_squared_error', \n",
    "                           verbose = 1, n_jobs = -1)\n",
    "\n",
    "grid_search.fit(X_train[best_var3], y_train)\n",
    "\n",
    "print(\"Best parameters : \", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "X_test['18~20_ride'] = best_model.predict(X_test[best_var3])\n",
    "X_test[['id','18~20_ride']].to_csv(\"lgb_gridCV_best_var3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f1f59-e6c0-409c-8980-937922d86531",
   "metadata": {},
   "source": [
    "## best_var3으로 학습한 LightGBM (Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754ef7f-5180-4bb1-ac61-1ad41e0ea8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"n_estimators\": 500,\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"dart\",\n",
    "        \"bagging_freq\": 1,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.8, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.8, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 50),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0, 0.1),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0, 0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 10)\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    scores = cross_val_score(model, X_train[best_var3], y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # 평균 RMSE 반환 (최소화하기 위해 - 붙임)\n",
    "    return -scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials = 100)  # 최적화 시도 횟수 100\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "\n",
    "best_model = lgb.LGBMRegressor(**study.best_params)\n",
    "best_model.fit(X_train[best_var3], y_train)\n",
    "X_test['18~20_ride'] = best_model.predict(X_test[best_var3])\n",
    "X_test[['id','18~20_ride']].to_csv(\"lgb_optuna_best_var3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f704b-a76f-4df0-9ffc-75e9e7e77c4d",
   "metadata": {},
   "source": [
    "## best_var1으로 학습한 RandomForest (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3230e-ba07-40ea-8b2c-ca23a3fa117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth = 10, min_samples_leaf = 4, min_samples_split = 10, max_features = 'auto',random_state=123)\n",
    "rf_model.fit(X_train[best_var1], y_train)\n",
    "\n",
    "X_test['18~20_ride'] = rf_model.predict(X_test[best_var1])\n",
    "X_test[['id','18~20_ride']].to_csv(\"rf_gridCV_best_var1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3768c6c5-d6d7-4e2d-bbc1-78837d86dded",
   "metadata": {},
   "source": [
    "## best_var1으로 학습한 RandomForest (Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0b4f6-4e4f-4986-a44f-ef6a1681108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth = 10, min_samples_leaf = 2, min_samples_split = 3, max_features = 'auto',random_state=123)\n",
    "rf_model.fit(X_train[best_var1], y_train)\n",
    "\n",
    "X_test['18~20_ride'] = rf_model.predict(X_test[best_var1])\n",
    "X_test[['id','18~20_ride']].to_csv(\"rf_optuna_best_var1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74258b5e-c274-40a9-ace0-e9f2736e62ba",
   "metadata": {},
   "source": [
    "## best_var3으로 학습한 RandomForest (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a211fad9-a941-48a3-b15b-a55fcefbe40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators = 200, max_depth = 10, min_samples_leaf = 1, min_samples_split = 2, max_features = 'sqrt',random_state=123)\n",
    "rf_model.fit(X_train[best_var3], y_train)\n",
    "\n",
    "X_test['18~20_ride'] = rf_model.predict(X_test[best_var3])\n",
    "X_test[['id','18~20_ride']].to_csv(\"rf_gridCV_best_var3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff962e-38fa-4ba7-9e8b-957dfc19c43f",
   "metadata": {},
   "source": [
    "## best_var3으로 학습한 RandomForest (Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9773904-47d5-4db3-a904-25ddb02a63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators = 167, max_depth = 9, min_samples_leaf = 2, min_samples_split = 8, max_features = 'auto',random_state=123)\n",
    "rf_model.fit(X_train[best_var3], y_train)\n",
    "\n",
    "X_test['18~20_ride'] = rf_model.predict(X_test[best_var3])\n",
    "X_test[['id','18~20_ride']].to_csv(\"rf_gridCV_best_var3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7546467-9501-4de2-9fb4-3d15341c3e5b",
   "metadata": {},
   "source": [
    "## 각 파일 concat 해 평균 값 구하고 dacon에 제출하여 rmse 값 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67254e0e-bd72-4f38-b1dc-1872bd4ceee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1b24f-3d57-44a8-bbd8-c69fadd31f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=pd.read_csv(\"lgb_gridCV_best_var1.csv\")\n",
    "B=pd.read_csv(\"rf_gridCV_best_var1.csv\")\n",
    "C= pd.read_csv(\"lgb_gridCV_best_var3.csv\")\n",
    "D=pd.read_csv(\"rf_gridCV_best_var3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893471b9-d2a0-465b-83c2-eb2d493e5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A+B \n",
    "combined = pd.concat([A, B])\n",
    "\n",
    "# id별로 그룹화하고 평균 계산\n",
    "result = combined.groupby('id')['18~20_ride'].mean().reset_index()\n",
    "\n",
    "result.to_csv(\"A+B.csv\",index=False)\n",
    "\n",
    "#A+C\n",
    "combined = pd.concat([A, C])\n",
    "\n",
    "# id별로 그룹화하고 평균 계산\n",
    "result = combined.groupby('id')['18~20_ride'].mean().reset_index()\n",
    "result.to_csv(\"A+C.csv\",index=False)\n",
    "\n",
    "#A+D\n",
    "combined = pd.concat([A, D])\n",
    "\n",
    "# id별로 그룹화하고 평균 계산\n",
    "result = combined.groupby('id')['18~20_ride'].mean().reset_index()\n",
    "result.to_csv(\"A+D.csv\",index=False)\n",
    "\n",
    "#B+C\n",
    "combined = pd.concat([B, C])\n",
    "\n",
    "# id별로 그룹화하고 평균 계산\n",
    "result = combined.groupby('id')['18~20_ride'].mean().reset_index()\n",
    "result.to_csv(\"B+C.csv\",index=False)\n",
    "\n",
    "# B+D\n",
    "# 데이터 합치기\n",
    "combined = pd.concat([B, D])\n",
    "\n",
    "# id별로 그룹화하고 평균 계산\n",
    "result = combined.groupby('id')['18~20_ride'].mean().reset_index()\n",
    "result.to_csv(\"B+D.csv\",index=False)\n",
    "\n",
    "#C+D\n",
    "combined = pd.concat([C, D])\n",
    "\n",
    "# id별로 그룹화하고 평균 계산\n",
    "result = combined.groupby('id')['18~20_ride'].mean().reset_index()\n",
    "result.to_csv(\"C+D.csv\",index=False)\n",
    "\n",
    "#A+B+C\n",
    "combined = pd.concat([A,B,C])\n",
    "\n",
    "# id별로 그룹화하고 평균 계산\n",
    "result = combined.groupby('id')['18~20_ride'].mean().reset_index()\n",
    "result.to_csv(\"A+B+C.csv\",index=False)\n",
    "\n",
    "#A+B+D\n",
    "combined = pd.concat([A,B,D])\n",
    "# id별로 그룹화하고 평균 계산\n",
    "result = combined.groupby('id')['18~20_ride'].mean().reset_index()\n",
    "result.to_csv(\"A+B+D.csv\",index=False)\n",
    "\n",
    "#B+C+D\n",
    "combined = pd.concat([B,C,D])\n",
    "# id별로 그룹화하고 평균 계산\n",
    "result = combined.groupby('id')['18~20_ride'].mean().reset_index()\n",
    "result.to_csv(\"B+C+D.csv\",index=False)\n",
    "\n",
    "#A+C+D\n",
    "combined = pd.concat([A,C,D])\n",
    "# id별로 그룹화하고 평균 계산\n",
    "result = combined.groupby('id')['18~20_ride'].mean().reset_index()\n",
    "result.to_csv(\"A+C+D.csv\",index=False)\n",
    "\n",
    "#A+B+C+D\n",
    "combined = pd.concat([A,B,C,D])\n",
    "# id별로 그룹화하고 평균 계산\n",
    "result = combined.groupby('id')['18~20_ride'].mean().reset_index()\n",
    "result.to_csv(\"A+B+C+D.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7453006-bb53-4692-be13-f4f7f70c89eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add0a3a-0236-42b2-ba9f-5b3727cecd31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d5cfd-f131-484d-a0df-6b673590dccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
